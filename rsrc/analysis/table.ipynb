{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "391af479",
   "metadata": {},
   "outputs": [],
   "source": [
    "## need to adjust output directory,result directory and baseline_directory before running the code\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "pa_list=[38.30,42.03,44.76]\n",
    "pe=[7.5,17.5,22.5,27.5,32.5]\n",
    "b=[0,10,15,20,25]\n",
    "pee=7.5\n",
    "kappa=2.094215255 \n",
    "zeta              = 1.66e-4*1e11\n",
    "\n",
    "pa=pa_list[1]\n",
    "\n",
    "output_directory=\"section7_2_78sites\\\\\"\n",
    "baseline_directory=f\"section7_2_78sites\\\\gams\\\\p_a_{pa}_p_e_{pe[0]}\"\n",
    "gams_directory=\"section7_2_78sites\\\\gams\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(\n",
    "    result_directory\n",
    "):\n",
    "    \n",
    "    os.chdir(result_directory)\n",
    "    \n",
    "    dfz= pd.read_csv('amazon_data_z.dat', delimiter='\\t')\n",
    "    dfz=dfz.drop('T/R ', axis=1)\n",
    "    dfz_np =dfz.to_numpy()[1:]\n",
    "\n",
    "    dft= pd.read_csv('theta.txt',header=None)\n",
    "    dft_np=dft.to_numpy().T\n",
    "\n",
    "    dfx= pd.read_csv('amazon_data_x.dat', delimiter='\\t')\n",
    "    dfx=dfx.drop('T   ', axis=1)\n",
    "    dfx_np =dfx.to_numpy()\n",
    "    dfxdot=np.diff(dfx_np,axis=0)\n",
    "\n",
    "    dfu= pd.read_csv('amazon_data_u.dat', delimiter='\\t')\n",
    "    dfu=dfu.drop('T/R ', axis=1)\n",
    "    dfu_np =dfu.to_numpy()\n",
    "\n",
    "    dfv= pd.read_csv('amazon_data_v.dat', delimiter='\\t')\n",
    "    dfv=dfv.drop('T/R ', axis=1)\n",
    "    dfv_np =dfv.to_numpy()\n",
    "    \n",
    "    return(\n",
    "        dfz_np,\n",
    "        dft_np,\n",
    "        dfxdot,\n",
    "        dfu_np,\n",
    "        dfv_np\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78978855",
   "metadata": {},
   "source": [
    "## Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fdedfb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pengyu\\AppData\\Local\\Temp\\ipykernel_13752\\66244404.py:60: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_code = results_df.to_latex(index=False)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for j in range(5):\n",
    "\n",
    "    order=j\n",
    "    \n",
    "    result_directory=gams_directory+f\"p_a_{pa}_p_e_{pe[order]}\"\n",
    "    \n",
    "    (   dfz_np,\n",
    "        dft_np,\n",
    "        dfxdot,\n",
    "        dfu_np,\n",
    "        dfv_np\n",
    "        )   =   read_file(result_directory)\n",
    "    \n",
    "    \n",
    "    results_AO = []\n",
    "    for i in range(200):\n",
    "        result_AO =pa*np.dot(dfz_np[i], dft_np[0])/((1+0.02)**(i+1))\n",
    "        results_AO.append(result_AO)\n",
    "    total_AO = np.sum(results_AO)\n",
    "    \n",
    "    results_NT = []\n",
    "    for i in range(200):\n",
    "        result_NT =-b[order]*(kappa*np.sum(dfz_np[i])-dfxdot[i])/((1+0.02)**(i+1))\n",
    "        results_NT.append(result_NT)\n",
    "    total_NT = np.sum(results_NT)\n",
    "    \n",
    "    results_CS = []\n",
    "    for i in range(200):\n",
    "        result_CS =-pee*(kappa*np.sum(dfz_np[i])-dfxdot[i])/((1+0.02)**(i+1))\n",
    "        results_CS.append(result_CS)\n",
    "    total_CS = np.sum(results_CS)\n",
    "    \n",
    "    results_AC = []\n",
    "    for i in range(200):\n",
    "        result_AC =(zeta/2)*(np.sum(dfu_np[i])+np.sum(dfv_np[i]))**2/((1+0.02)**(i+1))\n",
    "        results_AC.append(result_AC)\n",
    "    total_AC = np.sum(results_AC)\n",
    "    \n",
    "    total_PV=total_AO+total_NT+total_CS-total_AC\n",
    "    \n",
    "    iteration_results = {\n",
    "        \"pa\":pa,\n",
    "        \"pe\":pe[order],\n",
    "        \"b\":b[order],\n",
    "        \"total_AO\": total_AO,\n",
    "        \"total_NT\": total_NT,\n",
    "        \"total_CS\": total_CS,\n",
    "        \"total_AC\": total_AC,\n",
    "        \"total_PV\": total_PV\n",
    "    }\n",
    "\n",
    "    # Append the dictionary to the results list\n",
    "    results.append(iteration_results)\n",
    "    \n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "results_df.to_csv(output_directory+\"results_table1.csv\", index=False)\n",
    "latex_code = results_df.to_latex(index=False)\n",
    "\n",
    "# Optionally, save the LaTeX code to a file\n",
    "with open(output_directory+\"results_table1.tex\", \"w\") as file:\n",
    "    file.write(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641e083b",
   "metadata": {},
   "source": [
    "## Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b4856d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pengyu\\AppData\\Local\\Temp\\ipykernel_13752\\2642917604.py:45: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  total_EC=total_NT2/(total_NCE-total_NCE_base)*100\n",
      "C:\\Users\\pengyu\\AppData\\Local\\Temp\\ipykernel_13752\\2642917604.py:64: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_code = results_df2.to_latex(index=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "os.chdir(baseline_directory)\n",
    "\n",
    "dfz= pd.read_csv('amazon_data_z.dat', delimiter='\\t')\n",
    "dfz=dfz.drop('T/R ', axis=1)\n",
    "dfz_np =dfz.to_numpy()[1:]\n",
    "\n",
    "dfx= pd.read_csv('amazon_data_x.dat', delimiter='\\t')\n",
    "dfx=dfx.drop('T   ', axis=1)\n",
    "dfx_np =dfx.to_numpy()\n",
    "dfxdot=np.diff(dfx_np,axis=0)\n",
    "\n",
    "results_NCE_base = []\n",
    "for i in range(30):\n",
    "    result_NCE_base =-kappa*np.sum(dfz_np[i])+dfxdot[i]\n",
    "    results_NCE_base.append(result_NCE_base)\n",
    "total_NCE_base = np.sum(results_NCE_base)*100\n",
    "\n",
    "\n",
    "results_table2=[]\n",
    "for j in range(5):\n",
    "    \n",
    "    order=j\n",
    "    \n",
    "    result_directory=gams_directory+f\"p_a_{pa}_p_e_{pe[order]}\"\n",
    "    \n",
    "    (   dfz_np,\n",
    "        dft_np,\n",
    "        dfxdot,\n",
    "        dfu_np,\n",
    "        dfv_np\n",
    "        )   =   read_file(result_directory)\n",
    "    \n",
    "    results_NCE = []\n",
    "    for i in range(30):\n",
    "        result_NCE =-kappa*np.sum(dfz_np[i])+dfxdot[i]\n",
    "        results_NCE.append(result_NCE)\n",
    "    total_NCE = np.sum(results_NCE)*100\n",
    "\n",
    "    results_NT2 = []\n",
    "    for i in range(30):\n",
    "        result_NT2 =-b[order]*(kappa*np.sum(dfz_np[i])-dfxdot[i])\n",
    "        results_NT2.append(result_NT2)\n",
    "    total_NT2 = np.sum(results_NT2)\n",
    "\n",
    "    total_EC=total_NT2/(total_NCE-total_NCE_base)*100\n",
    "    \n",
    "    \n",
    "    iteration_results = {\n",
    "        \"pa\":pa,\n",
    "        \"pe\":pe[order],\n",
    "        \"b\":b[order],\n",
    "        \"total_NCE\": total_NCE,\n",
    "        \"total_NT2\": total_NT2,\n",
    "        \"total_EC\": total_EC\n",
    "    }\n",
    "\n",
    "    # Append the dictionary to the results list\n",
    "    results_table2.append(iteration_results)\n",
    "    \n",
    "results_df2 = pd.DataFrame(results_table2)\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "results_df2.to_csv(output_directory+\"results_table2.csv\", index=False)\n",
    "latex_code = results_df2.to_latex(index=False)\n",
    "\n",
    "# Optionally, save the LaTeX code to a file\n",
    "with open(output_directory+\"results_table2.tex\", \"w\") as file:\n",
    "    file.write(latex_code)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4068662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba81657c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4498dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec4bd7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2524c64a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
