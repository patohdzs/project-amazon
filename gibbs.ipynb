{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from scipy.stats import invgamma, norm,gamma\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "municipal_gamma_df = gpd.read_file(\"C:\\\\Users\\\\pengyu\\\\Desktop\\\\correlation\\\\project-amazon\\\\data\\\\calibration\\\\hmc\\\\gamma_reg_site_1043.geojson\")\n",
    "\n",
    "X = municipal_gamma_df.iloc[:, 0:6].values  # Columns 1 to 6 as X\n",
    "Y = municipal_gamma_df.iloc[:, 6].values    # Column 7 as Y\n",
    "site_ids = municipal_gamma_df.iloc[:, 7].values -1   # Column 8 as site_ids\n",
    "\n",
    "np.random.seed(45)\n",
    "# beta_prior_mean = (6.245,0.019,-0.066,1.188,-0.05,1.11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def gibbs_sampling_with_data(X, Y, site_ids, n_iterations=100000, beta_prior_mean=None, beta_prior_cov=None, \n",
    "                             eta_prior_shape=2, eta_prior_scale=1, nu_prior_shape=2, nu_prior_scale=1):\n",
    "    n_data, n_features = X.shape\n",
    "    n_sites = len(np.unique(site_ids))\n",
    "    \n",
    "    # Initialize priors\n",
    "    if beta_prior_mean is None:\n",
    "        beta_prior_mean = np.zeros(n_features)\n",
    "    if beta_prior_cov is None:\n",
    "        beta_prior_cov = np.eye(n_features)   # Large prior variance\n",
    "    \n",
    "    # Initialize Gibbs sampling arrays\n",
    "    beta_samples = np.zeros((n_iterations, n_features))\n",
    "    eta_samples = np.zeros(n_iterations)\n",
    "    nu_samples = np.zeros(n_iterations)\n",
    "    V_samples = np.zeros((n_iterations, n_sites))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # Initial values based on prior\n",
    "    beta_current = np.random.multivariate_normal(beta_prior_mean, beta_prior_cov)\n",
    "    eta_current = gamma.rvs(a=eta_prior_shape, scale=1/eta_prior_scale)\n",
    "    nu_current = gamma.rvs(a=nu_prior_shape, scale=1/nu_prior_scale)\n",
    "    V_current = np.zeros(n_sites)+0.01\n",
    "    \n",
    "    # Gibbs sampler\n",
    "    for i in range(n_iterations):\n",
    "        # Step i: Draw beta conditioned on V, eta, and data\n",
    "        precision_beta = eta_current * (X.T @ X)\n",
    "        mean_beta = np.linalg.inv(precision_beta) @ ( eta_current * X.T @ (Y - V_current[site_ids]))\n",
    "        beta_current = np.random.multivariate_normal(mean_beta, np.linalg.inv(precision_beta))\n",
    "        beta_samples[i, :] = beta_current\n",
    "        \n",
    "        # Step ii: Draw eta conditioned on V and data\n",
    "        residuals = Y - X @ beta_current - V_current[site_ids]\n",
    "        eta_shape_post =    n_data / 2\n",
    "        eta_scale_post =  0.5 * np.sum(residuals**2)\n",
    "        eta_current = gamma.rvs(a=eta_shape_post, scale=1/eta_scale_post)\n",
    "        eta_samples[i] = eta_current\n",
    "        \n",
    "        # Step iii: Draw nu conditioned on V\n",
    "        nu_shape_post =  n_sites / 2\n",
    "        nu_scale_post =  0.5 * np.sum(V_current**2)\n",
    "        nu_current = gamma.rvs(a=nu_shape_post, scale=1/nu_scale_post)\n",
    "        nu_samples[i] = nu_current\n",
    "        \n",
    "        # nu_current = 1e10\n",
    "        # nu_samples[i] = nu_current\n",
    "        \n",
    "        # Step iv: Draw V_j conditioned on beta, nu, eta, and data\n",
    "        for j in range(n_sites):\n",
    "            site_mask = site_ids == j\n",
    "            n_j = np.sum(site_mask)\n",
    "            V_bar_j = np.mean(Y[site_mask] - X[site_mask] @ beta_current)\n",
    "            mean_V_j = (n_j * eta_current * V_bar_j) / (n_j * eta_current + nu_current)\n",
    "            precision_V_j = n_j * eta_current + nu_current\n",
    "            V_current[j] = np.random.normal(mean_V_j, np.sqrt(1 / precision_V_j))\n",
    "        V_samples[i, :] = V_current\n",
    "    \n",
    "    \n",
    "    beta_samples_final = beta_samples[50000:,:]\n",
    "    eta_samples_final = eta_samples[50000:]\n",
    "    nu_samples_final = nu_samples[50000:]\n",
    "    V_samples_final = V_samples[50000:,:]\n",
    "    \n",
    "    # Posterior means\n",
    "    beta_posterior_mean = beta_samples_final.mean(axis=0)\n",
    "    eta_posterior_mean = eta_samples_final.mean()\n",
    "    nu_posterior_mean = nu_samples_final.mean()\n",
    "    \n",
    "    return beta_posterior_mean, eta_posterior_mean, nu_posterior_mean, beta_samples_final, eta_samples_final, nu_samples_final, V_samples_final\n",
    "\n",
    "# Run Gibbs sampling with the extracted data\n",
    "# Assuming X, Y, and site_ids are already defined\n",
    "beta_posterior_mean, eta_posterior_mean, nu_posterior_mean, beta_samples, eta_samples, nu_samples, V_samples = gibbs_sampling_with_data(X, Y, site_ids)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Posterior mean of beta: {beta_posterior_mean}\")\n",
    "print(f\"Posterior mean of eta: {eta_posterior_mean}\")\n",
    "print(f\"Posterior mean of nu: {nu_posterior_mean}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(beta_samples[:, 0], bins=100, density=True, alpha=0.75)\n",
    "plt.title(r'Posterior of $\\beta_1$')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(beta_samples[:, 1], bins=100, density=True, alpha=0.75)\n",
    "plt.title(r'Posterior of $\\beta_2$')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(beta_samples[:, 2], bins=100, density=True, alpha=0.75)\n",
    "plt.title(r'Posterior of $\\beta_3$')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(beta_samples[:, 3], bins=100, density=True, alpha=0.75)\n",
    "plt.title(r'Posterior of $\\beta_4$')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(beta_samples[:, 4], bins=100, density=True, alpha=0.75)\n",
    "plt.title(r'Posterior of $\\beta_5$')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(beta_samples[:, 5], bins=100, density=True, alpha=0.75)\n",
    "plt.title(r'Posterior of $\\beta_6$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "corr_sample=1/nu_samples/(1/nu_samples+1/eta_samples)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(eta_samples, bins=100, density=True, alpha=0.75)\n",
    "plt.title(r'Posterior of $\\eta$')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(nu_samples, bins=100, density=True, alpha=0.75)\n",
    "plt.title(r'Posterior of $\\nu$')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(corr_sample, bins=100, density=True, alpha=0.75)\n",
    "plt.title(r'Posterior of correlation')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"beta7\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df=pd.read_csv(\"gamma.csv\").to_numpy()[:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "\n",
    "for i in range(6):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(df[:, i], bins=100, density=True, alpha=0.75,color = 'blue',label = 'iid model')\n",
    "    plt.hist(beta_samples[:, i], bins=100, density=True, alpha=0.75, color = 'red', label = 'random effect model')\n",
    "    plt.title(r'Posterior of $\\beta_'+str(i+1)+'$')\n",
    "    plt.legend()\n",
    "    plt.savefig('beta'+str(i+1)+'.png')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "beta_posterior_mean = np.mean(beta_samples,axis=0)\n",
    "beta_posterior_variance = np.cov(beta_samples, rowvar=False, ddof=1)  # ddof=1 for unbiased estimate\n",
    "beta_posterior = np.random.multivariate_normal(beta_posterior_mean, beta_posterior_variance,size=50000)\n",
    "\n",
    "\n",
    "\n",
    "eta_posterior_mean = np.mean(eta_samples)\n",
    "eta_posterior_variance = np.var(eta_samples, ddof=1)  \n",
    "eta_shape_post = (eta_posterior_mean ** 2) / eta_posterior_variance\n",
    "eta_scale_post = eta_posterior_variance / eta_posterior_mean\n",
    "eta_posterior = gamma.rvs(a=eta_shape_post, scale=eta_scale_post, size=50000)\n",
    "\n",
    "\n",
    "\n",
    "nu_posterior_mean = np.mean(nu_samples)\n",
    "nu_posterior_variance = np.var(nu_samples, ddof=1)  \n",
    "nu_shape_post = (nu_posterior_mean ** 2) / nu_posterior_variance\n",
    "nu_scale_post = nu_posterior_variance / nu_posterior_mean\n",
    "nu_posterior = gamma.rvs(a=nu_shape_post, scale=nu_scale_post, size=50000)\n",
    "\n",
    "\n",
    "V_posterior_mean = np.mean(V_samples,axis=0)\n",
    "V_posterior_variance = np.var(V_samples, ddof=1,axis=0)\n",
    "V_posterior = np.random.normal(V_posterior_mean, np.sqrt(V_posterior_variance),size=(50000,78))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "\n",
    "# Add beta parameters\n",
    "for i in range(len(beta_posterior_mean)):\n",
    "    data.append({'Parameter': f'beta_{i+1}', 'Posterior Mean': beta_posterior_mean[i], 'Posterior Variance': None})\n",
    "    \n",
    "# Add beta variance (covariance matrix, flattened)\n",
    "for i in range(len(beta_posterior_mean)):\n",
    "    for j in range(len(beta_posterior_mean)):\n",
    "        data.append({'Parameter': f'var_beta_{i+1}_{j+1}', 'Posterior Mean': None, 'Posterior Variance': beta_posterior_variance[i, j]})\n",
    "\n",
    "# Add eta parameter\n",
    "data.append({'Parameter': 'eta', 'Posterior Mean': eta_posterior_mean, 'Posterior Variance': eta_posterior_variance})\n",
    "\n",
    "# Add nu parameter\n",
    "data.append({'Parameter': 'nu', 'Posterior Mean': nu_posterior_mean, 'Posterior Variance': nu_posterior_variance})\n",
    "\n",
    "# Add V parameters\n",
    "for i in range(len(V_posterior_mean)):\n",
    "    data.append({'Parameter': f'V_{i+1}', 'Posterior Mean': V_posterior_mean[i], 'Posterior Variance': V_posterior_variance[i]})\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('posterior_means_and_variances.csv', index=False)\n",
    "\n",
    "print(\"Posterior means and variances saved to 'posterior_means_and_variances.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_fit_df_1043 = gpd.read_file(\"C:\\\\Users\\\\pengyu\\\\Desktop\\\\correlation\\\\project-amazon\\\\data\\\\calibration\\\\hmc\\\\gamma_data_site_1043.geojson\")\n",
    "X_fit = gamma_fit_df_1043.iloc[:, 0:6].values  # Columns 1 to 6 as X\n",
    "id_fit = gamma_fit_df_1043.iloc[:, 7].values  # Columns 1 to 6 as X\n",
    "gamma_fit_df_1043 = np.mean(np.exp(X_fit @ beta_samples.T + V_samples[:, id_fit-1].T),axis=1)\n",
    "gamma_fit_df_1043_df = pd.DataFrame(gamma_fit_df_1043, columns=['gamma_fit'])\n",
    "gamma_fit_df_1043_df.to_csv('gamma_fit_1043.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_fit_df_78 = gpd.read_file(\"C:\\\\Users\\\\pengyu\\\\Desktop\\\\correlation\\\\project-amazon\\\\data\\\\calibration\\\\hmc\\\\gamma_data_site_78.geojson\")\n",
    "X_fit = gamma_fit_df_78.iloc[:, 0:6].values  # Columns 1 to 6 as X\n",
    "id_fit = gamma_fit_df_78.iloc[:, 7].values  # Columns 1 to 6 as X\n",
    "gamma_fit_df_78 = np.mean(np.exp(X_fit @ beta_samples.T + V_samples[:,].T),axis=1)\n",
    "gamma_fit_df_78_df = pd.DataFrame(gamma_fit_df_78, columns=['gamma_fit'])\n",
    "gamma_fit_df_78_df.to_csv('gamma_fit_78.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
